# LLM Context Demo

Une application web √©ducative interactive d√©montrant comment le contexte affecte les r√©ponses des Large Language Models (LLM). Cet outil aide les d√©veloppeurs et passionn√©s d'IA √† comprendre le r√¥le crucial du contexte dans les interactions avec les LLM.

## üåê D√©mo en ligne

Visitez l'application : [https://agentmaurice.github.io/llm-context-demo/](https://agentmaurice.github.io/llm-context-demo/)

![QR Code](https://api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://github.com/agentmaurice/llm-context-demo)

## üéØ Objectif

Cette application offre une exp√©rience pratique avec diff√©rents concepts LLM :
- **Gestion du contexte** : Observez comment diff√©rents contextes influencent les r√©ponses
- **Prompts syst√®me** : Apprenez √† fa√ßonner le comportement du mod√®le
- **Few-shot learning** : Comprenez l'apprentissage par exemples
- **Ajustement des param√®tres** : Exp√©rimentez avec temp√©rature et limites de tokens
- **Injection de prompt** : Testez les consid√©rations de s√©curit√©
- **RAG** : D√©couvrez la g√©n√©ration augment√©e par r√©cup√©ration
- **MCP** : Explorez le Model Context Protocol pour les appels d'outils

## ‚ú® Fonctionnalit√©s

### 12 √âtapes √©ducatives progressives

0. **Anatomie d'un appel API** : Structure compl√®te d'une requ√™te HTTP vers un LLM
1. **Sans contexte** : Requ√™tes de base sans contexte
2. **R√¥le syst√®me** : Ajout d'un message syst√®me pour d√©finir le comportement
3. **Historique de conversation** : Construction bas√©e sur les interactions pr√©c√©dentes
4. **Few-shot learning** : Apprentissage du format de sortie par exemples
5. **Instructions de formatage** : Contr√¥le pr√©cis de la structure de r√©ponse
6. **Conflits de contexte** : Gestion d'instructions contradictoires
7. **RAG (Retrieval-Augmented Generation)** : Injection de donn√©es dans le contexte
8. **Contr√¥le de temp√©rature** : Ajustement interactif des param√®tres
9. **Long contexte** : Gestion d'un historique de conversation √©tendu
10. **Injection de prompt** : Tests de s√©curit√© contre les entr√©es malveillantes
11. **MCP (Model Context Protocol)** : Orchestration d'appels d'outils externes dynamiques

### 2 Outils Bonus

- **Comparateur** : Comparaison c√¥te √† c√¥te de deux contextes diff√©rents
- **√âditeur libre** : Construisez votre propre contexte message par message

### Interface utilisateur moderne

- **Navigation lat√©rale avec ic√¥nes** : Interface shadcn/ui √©l√©gante avec ic√¥nes lucide-react
- **Questions sugg√©r√©es** : Chaque √©tape propose une question pertinente pour tester le concept
- **R√©initialisation automatique** : Les champs se vident automatiquement lors du changement d'√©tape
- **Mini-conclusions** : Explication de ce qu'il faut observer apr√®s chaque r√©sultat
- **Visualisation du contexte** : Voir exactement le JSON envoy√© √† l'API
- **R√©ponse en temps r√©el** : Affichage complet des r√©ponses API
- **Page d'accueil** : Pr√©sentation compl√®te avec QR code et lien GitHub
- **Cl√© API persistante** : Votre cl√© OpenAI est stock√©e localement dans votre navigateur

## üöÄ D√©marrage

### Pr√©requis

- Node.js (v18 ou sup√©rieur)
- Une cl√© API OpenAI ([Obtenez-en une ici](https://platform.openai.com/api-keys))

### Installation

1. Clonez le d√©p√¥t :
```bash
git clone https://github.com/agentmaurice/llm-context-demo.git
cd llm-context-demo
```

2. Installez les d√©pendances :
```bash
npm install
```

3. D√©marrez le serveur de d√©veloppement :
```bash
npm run dev
```

4. Ouvrez votre navigateur et acc√©dez √† `http://localhost:5173/llm-context-demo/`

### Build pour production

```bash
npm run build
npm run preview
```

### D√©ploiement sur GitHub Pages

Le projet est configur√© pour √™tre d√©ploy√© automatiquement sur GitHub Pages via GitHub Actions. Chaque push sur la branche `main` d√©clenche un d√©ploiement automatique.

## üîë Configuration de la cl√© API

1. Au premier lancement, vous serez invit√© √† entrer votre cl√© API OpenAI
2. La cl√© est stock√©e dans le localStorage de votre navigateur (jamais envoy√©e √† un serveur tiers, uniquement √† OpenAI)
3. Vous pouvez reconfigurer votre cl√© API √† tout moment via le lien dans la barre lat√©rale ou la page de configuration

**Note de s√©curit√©** : Votre cl√© API reste dans votre navigateur. Cette application effectue des appels directs √† OpenAI depuis votre navigateur.

## üõ†Ô∏è Stack technologique

- **React 18** - Framework UI avec hooks
- **Vite** - Outil de build et serveur de d√©veloppement
- **React Router** - Routage c√¥t√© client
- **Tailwind CSS** - Styling utility-first
- **shadcn/ui** - Composants UI modernes (Button, Badge, Separator)
- **Lucide React** - Biblioth√®que d'ic√¥nes
- **OpenAI API** - Mod√®les GPT-4 (gpt-4o et gpt-4-turbo)
- **GitHub Actions** - CI/CD pour d√©ploiement automatique

## üìö Parcours d'apprentissage

### Ordre recommand√© pour les d√©butants

1. Commencez par **l'√âtape 0** (Anatomie d'un appel API) pour comprendre la structure technique
2. Continuez avec **l'√âtape 1** (Sans contexte) pour voir le comportement de base
3. Progressez √† travers les **√âtapes 2-3** pour comprendre les r√¥les syst√®me et l'historique
4. Essayez les **√âtapes 4-5** pour apprendre les techniques de contr√¥le de sortie
5. Exp√©rimentez avec **l'√âtape 8** pour comprendre les effets de la temp√©rature
6. Utilisez **l'√âditeur libre** pour cr√©er vos propres exp√©riences

### Pour les utilisateurs avanc√©s

- **√âtape 6** : √âtudiez la gestion des priorit√©s de contexte
- **√âtape 7** : Comprenez l'impl√©mentation du RAG
- **√âtape 9** : Testez la gestion des limites de tokens
- **√âtape 10** : Explorez les vuln√©rabilit√©s de s√©curit√©
- **√âtape 11** : D√©couvrez le Model Context Protocol et l'orchestration d'outils
- **Comparateur** : Testez A/B diff√©rentes approches

## üéì Concepts cl√©s expliqu√©s

### Fen√™tre de contexte (Context Window)
L'historique de conversation et les instructions envoy√©s avec chaque requ√™te API. Tout ce qui est dans le contexte affecte la r√©ponse du mod√®le.

### Prompts syst√®me
Messages sp√©ciaux qui d√©finissent le r√¥le, le comportement et les contraintes de l'assistant. Ils ont g√©n√©ralement une priorit√© plus √©lev√©e que les messages utilisateur.

### Few-shot Learning
Fournir des exemples dans le contexte pour enseigner au mod√®le un pattern ou format sp√©cifique sans instructions explicites. Le mod√®le apprend par l'exemple.

### Temp√©rature
Contr√¥le le caract√®re al√©atoire des r√©ponses :
- **0.0** : R√©ponses d√©terministes et concentr√©es
- **1.0** : √âquilibre entre cr√©ativit√© et coh√©rence (par d√©faut)
- **2.0** : Cr√©ativit√© et al√©atoire maximum

### RAG (Retrieval-Augmented Generation)
Int√©gration de donn√©es pertinentes dans le contexte pour ancrer les r√©ponses dans des informations sp√©cifiques plut√¥t que de s'appuyer uniquement sur les donn√©es d'entra√Ænement. Les donn√©es sont inject√©es AVANT l'appel au LLM.

### MCP (Model Context Protocol)
Protocole standardis√© permettant aux LLMs d'appeler dynamiquement des outils externes via un orchestrateur. Contrairement au RAG, le LLM DEMANDE les donn√©es PENDANT sa g√©n√©ration. Le MCP suit le protocole JSON-RPC 2.0 avec deux phases principales :
- **tools/list** : D√©couverte des outils disponibles
- **tools/call** : Ex√©cution d'un outil sp√©cifique

### Injection de prompt
Vuln√©rabilit√© de s√©curit√© o√π un utilisateur malveillant tente de contourner les instructions syst√®me en injectant ses propres commandes. Protection via instructions syst√®me fermes et validation des entr√©es.

## ü§ù Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† :
- Signaler des bugs
- Sugg√©rer de nouvelles √©tapes √©ducatives
- Am√©liorer la documentation
- Soumettre des pull requests
- Traduire l'interface dans d'autres langues

## üìù Licence

Ce projet est open source et disponible √† des fins √©ducatives.

## ‚ö†Ô∏è Avertissement

Cette application utilise l'API OpenAI qui entra√Æne des co√ªts bas√©s sur l'utilisation. Veuillez surveiller votre utilisation de l'API et d√©finir des limites appropri√©es dans votre compte OpenAI.

**Co√ªts estim√©s** : Chaque requ√™te consomme des tokens (voir le champ `usage` dans les r√©ponses). Les √©tapes avec long contexte (9, 11) consomment plus de tokens.

## üîó Ressources

- [Documentation API OpenAI](https://platform.openai.com/docs)
- [Guide Prompt Engineering](https://www.promptingguide.ai/)
- [Documentation React](https://react.dev/)
- [Documentation shadcn/ui](https://ui.shadcn.com/)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [Lucide Icons](https://lucide.dev/)

## üìß Contact

Pour des questions ou des retours, veuillez ouvrir une issue sur GitHub.

---

**Fait avec ‚ù§Ô∏è pour la communaut√© d'apprentissage de l'IA**

üåü **N'oubliez pas de mettre une √©toile au projet si vous l'avez trouv√© utile !**
